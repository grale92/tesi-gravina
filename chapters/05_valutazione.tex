\chapter{Valutazione dei risultati e confronto}

In questo capitolo vengono presentati e analizzati i risultati sperimentali ottenuti dalle due soluzioni implementate: il modello NER custom sviluppato con spaCy e il modello configurato tramite Google Cloud Document AI. L'obiettivo è confrontare le prestazioni dei due approcci sia dal punto di vista quantitativo, attraverso le metriche standard dei modelli di Named Entity Recognition, sia sotto il profilo qualitativo che progettuale, al fine di valutarne l'effettiva applicabilità nel contesto aziendale descritto nei capitoli precedenti.

Prima di esporre i risultati è necessario precisare alcune differenze nei dataset utilizzati per la valutazione. Per quanto riguarda Google Document AI, il modello è stato valutato su un insieme di 43 documenti. Il modello NER sviluppato con spaCy, invece, è stato valutato su 31 documenti. Tale discrepanza è dovuta al fatto che, durante l'implementazione delle fasi di pre-processing e segmentazione per la soluzione custom, l'analisi si è concentrata su un numero più ristretto di template documentali, in modo da valutare meglio l'efficacia delle migliorie introdotte e ridurre la variabilità.

È inoltre importante evidenziare che, nel caso del modello spaCy, la valutazione non avviene direttamente a livello di documento intero, ma su finestre testuali derivate dalla fase di segmentazione. Le metriche vengono quindi calcolate su tali frammenti di testo e non sui documenti nella loro interezza. Questo comporta che alcune entità possano comparire in più finestre appartenenti allo stesso documento, influenzando le statistiche aggregate e potenzialmente producendo valori più elevati rispetto a una valutazione effettuata a livello documentale.

Queste differenze metodologiche sono cruciali al fine di interpretare i risultati qualititivi ed il confronto tra le due soluzioni.

\section{Risultati sperimentali}

Dall'analisi delle metriche di valutazione a livello globale riportate in Figura~\ref{fig:overall_metrics}, emerge che a ottenere le migliori prestazioni è stato il modello custom realizzato con spaCy, ottenendo un F1-score di $0.96$, mentre la soluzione cloud-based si è attestata su un valore pari a $0.85$.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/compare_overall_metrics.png}
    \caption{Grafico di confronto metriche di valutazione dei modelli NER}
    \label{fig:overall_metrics}
\end{figure}

Il grafico evidenzia inoltre come la differenza tra i due modelli non sia limitata al solo F1-score, ma si distribuisca anche sulle componenti di precision e recall. Il modello spaCy mostra valori elevati e bilanciati su entrambe le metriche, mentre Document AI presenta una precision inferiore, a indicare una maggiore incidenza di falsi positivi.

Passando ad un'analisi più granulare, la Figura~\ref{fig:compare_entity_f1} riporta il confronto degli F1-score relativi ad alcune entità specifiche. Questo livello di dettaglio permette di comprendere non solo quale sia il modello mediamente più performante, ma anche su quali tipologie di informazione emergano le principali criticità.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/compare_entity_f1_clean.png}
    \caption{Grafico di confronto F1-score su specifiche entità}
    \label{fig:compare_entity_f1}
\end{figure}

Si osserva che le principali problematiche per il modello di Document AI si concentrano nell'estrazione delle informazioni relative alle prove (\texttt{TEXT\_NAME} e \texttt{TEXT\_METHOD}), oltre che al codice dell'articolo o prodotto coinvolto (\texttt{ARTICLE\_NO}).

Prima di trarre conclusioni definitive, è tuttavia necessario contestualizzare al meglio i risultati, tenendo conto delle differenze metodologiche delle due soluzioni.

\subsection{Il ruolo della riduzione di rumore}

Uno dei principali elementi per cui l'implementazione di spaCy ha ottenuto risultati migliori è rappresentato alle fasi di pre-processing e segmentazione implementate nella pipeline custom. Attraverso operazioni di pulizia e filtraggio sulle righe del file, sono state rimosse porzioni di documento non rilevanti ai fini applicativi, riducendo significativamente il rumore in ingresso al modello. I report utilizzati infatti, contengono intere sezioni che, pur essendo utili alla consultazione umana, non apportano alcun contributo all'estrazione delle entità di interesse. La definizione delle finestre contestuali ha permesso di isolare i frammenti annotabili, restringendo il campo operativo del modello.

Al contrario, il modello di Document AI è stato applicato all'intero documento PDF, senza un pre-filtraggio. Questo ha comportato una maggiore esposizione a contenuti non rilevanti, con conseguente aumento dei falsi positivi. Le entità effettivamente corrette infatti venivano generalmente individuate, ma a queste si aggiungevano rilevamenti addizionali non presenti nell'etichettatura manuale.

\subsection{Le occorrenze di dati ripetuti}

Un ulteriore aspetto che incide sulle performance riguarda la presenza di informazioni ripetute all'interno del documento. I report sono strutturati su più pagine e spesso reiterano le stesse entità in contesti differenti. Nel caso delle prove di laboratorio, i nomi dei test e i relativi metodi compaiono sia in tabelle analitiche dei risultati sperimentali, sia in tabelle riepilogative indicanti il successo o il fallimento delle prove.

Anche in questo caso, la segmentazione operata nella soluzione custom ha contribuito a limitare il problema, concentrando l'attenzione del modello solo sulle sezioni più informative e coerenti con lo schema di etichettatura definito.

\subsection{Il collegamento logico tra le entità}

Un aspetto rilevante nella progettazione del modello Document AI è stata la definizione di una struttura gerarchica delle entità. In particolare, per le prove di laboratorio è stata introdotta un entità padre rappresentante il test, con due entità figlie (\texttt{test\_name} e \texttt{test\_method}). Questo implica che il modello non debba soltanto riconoscere correttamente le singole porzioni di testo, ma anche stabilire un'associazione logica coerente tra di esse.

Tale vincolo aumenta la complessità del processo di estrazione e può influire nella precisione del modello. Tuttavia, questa impostazione offre un vantaggio applicativo significativo nella fase di post-processing che il modello spaCy non offre. Quest'ultimo infatti, non integra un meccanismo di associazione tra le entità, pertanto risulta più complicata la fase di post-processing e l'eventuale utilizzo applicativo dei dati ottenuti senza la definizione di un criterio associativo.

\section{Discussione e confronto tra le due soluzioni}

Alla luce dei risultati sperimentali presentati nella sezione precedente, è possibile effettuare un confronto strutturato tra i due approcci utilizzati. Il confronto non limita solo ai risultati ottenuti, ma prende in considerazione aspetti progettuali, architetturali ed anche economici che incidono significativamente sull'utilizzabilità della soluzione nel contesto applicativo di riferimento.

\subsection{Confronto prestazionale}

In primo luogo è necessario aprire una parentesi legata alle prestazioni ottenute dai due endpoint utilizzati per l'estrazione delle entità. Nella Tabella~\ref{tab:tempi_confronto} vengono riportate cinque esecuzioni a campione, ognuna effettuata con un file di input diverso, sia con l'endpoint che utilizza il modello custom, sia con quello che richiama i servizi cloud.

\begin{table}[h!]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Run} & \textbf{Document AI (sec)} & \textbf{spaCy (sec)} \\
\midrule
Run 1 & 13.107455 & 0.440606 \\
Run 2 & 8.403471 & 0.057668 \\
Run 3 & 9.953679 & 0.098521 \\
Run 4 & 9.918095 & 0.119696 \\
Run 5 & 8.981371 & 0.073017 \\
\midrule
\textbf{Media} & \textbf{10.072814} & \textbf{0.157902} \\
\bottomrule
\end{tabular}
\caption{Tempi di risposta dei due endpoint}
\label{tab:tempi_confronto}
\end{table}

Come prevedibile, in questo caso, le prestazioni a livello temporale mantenendo il modello all'interno dell'applicativo sono notevolmente migliori. Per quanto riguarda l'approccio gestito, l'\textit{overhead} è legato a vari fattori, tra cui:

\begin{itemize}
    \item Inizializzazione del client, solo durante la prima esecuzione
    \item Tempo di trasferimento del documento sul server
    \item Verifica dati di autenticazione
    \item Allocazione delle risorse per il processo
    \item Latenza di rete
\end{itemize}

\subsection{Confronto architetturale}

L'approccio custom garantisce un controllo completo sull'intera pipeline descritta nei capitolo precedenti. Tale controllo consente una maggiore aderenza a specifiche esigenze di dominio che come abbiamo visto porta a dei risultati tendenzialmente migliori in termini di qualità delle estrazioni, tuttavia all'aumentare della variablità dei dati di input può diventare complesso gestire tutte le logiche in modo funzionale e adattabile a tutti i contesti.

L'approccio su servizio gestito, invece, delega al provider cloud la complessità legata all'analisi del layout e al riconoscimento delle entità. Questo riduce sensibilmente l'effort iniziale e semplifica l'integrazione in un applicativo, ma introduce una dipendenza tecnologica e limita la possibilità di personalizzazione fine del modello.

Ciò che veramente rappresenta il beneficio principale di uno strumento complesso come quello utilizzato di Google, sono le potenzialità di definire associazioni logiche tra le etichette oltre che a creare etichette dedotte e non estratte direttamente dal testo. Questi due fattori rendono l'utilizzo i dati ottenuti molto più fruibili, in particolare rappresentano un plus notevole in fase di post-processing e utilizzo all'interno dell'applicativo poiché consentono di avere un output già ben strutturato su cui è possibile impostare delle logiche di ricerca dei dati più mirate.

\subsection{Confronto operativo}

Dal punto di vista operativo e ragionando nell'ottica di un'integrazione in un contesto industriale, emergono ulteriori punti da considerare:

\begin{itemize}
    \item \textbf{Scalabilità}: il servizio cloud offre scalabilità nativa e gestione automatica delle risorse, tuttavia l'integrazione applicativa è sempre un microservizio che richiede un'infrastruttura presente, che nel caso di utilizzo del modello custom deve supportare i processi di elaborazione richiesti dalla fase di addestramento e inferenza.
    \item \textbf{Costi}: il modello custom lega i suoi costi allo sviluppo iniziale ed alla manutenzione del flusso, ma non prevede costi per richiesta; il servizio cloud prevede invece una modalità \textit{pay-per-use}, ovvero legata al numero di richieste effettuate. Di conseguenza è necessario valutare anche la mole dell'utenza del prodotto perché con quest'ultima modalità i costi possono crescere esponenzialmente.
    \item \textbf{Sicurezza e controllo dei dati}: la soluzione custom mantiene l'intero ciclo di elaborazione all'interno dell'infrastruttura controllata, mentre l'approccio cloud prevede l'invio dei documenti e dei dati in esso contenuti a un sistema esterno; il tema legato ai dati necessita di un'analisi a parte che verrà approfondita nella sezione seguente.
    \item \textbf{Manutenibilità}: nel caso custom, aggiornamenti e miglioramenti sono tenuti sono controllo dal team di sviluppo, mentre nel caso dell'approccio cloud l'evoluzione del prodotto è demandata al provider, con tutte le conseguenze del caso (necessità di adattamento ai cambiamenti, dipendenza tecnologica, ecc\dots).
\end{itemize}

\subsection{Confronto sulla gestione dei dati}

Nel confrontare le due soluzioni, uno degli aspetti più rilevanti da tenere in considerazione -- e spesso sottovalutato -- è quello relativo alla protezione dei dati confidenziali ed ai vincoli relativi alla loro circolazione.

In questo caso i documenti oggetto di elaborazione non contengono dati personali in senso stretto, ma informazioni di natura industriale che rappresentano un patrimonio informativo sensibile per l'azienda, in quanto legato alla qualità del prodotto, alla conformità normativa e alla competitività sul mercato.

L'utilizzo di un servizio cloud per l'elaborazione dei documenti implica la trasmissione di questi dati verso infrastrutture esterne all'organizzazione. Dal punto di vista tecnico, questo introduce alcune considerazioni rilevanti:

\begin{itemize}
    \item perdita di controllo diretto sull'infrastruttura fisica che ospita i dati;
    \item dipendenza dalle policy di sicurezza e di gestione del provider;
    \item necessità di valutare dove vengono processati e archiviati i dati in base alle normative vigenti.
\end{itemize}

L'approccio custom, mantenendo l'intero flusso all'interno dell'infrastruttura consente di:

\begin{itemize}
    \item confinare i dati nel perimetro applicativo interno;
    \item ridurre l'esposizione verso sistemi esterni;
    \item garantire maggior controllo sulle modalità di conservazione e cancellazione dei documenti.
\end{itemize}

Pertanto nell'individuare una soluzione operativa è necessario nel caso ci si affidi ad un servizio cloud valutare questi aspetti tenendo conto del grado di controllo desiderato sulla circolazione di dati industriali, di eventuali vincoli di governance interna e accordi di riservatezza.